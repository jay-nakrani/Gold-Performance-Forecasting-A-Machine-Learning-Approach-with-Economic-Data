# -*- coding: utf-8 -*-
"""Copy of Gold_price_forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GgNDVW7JvuDOJ4_iuW4yZYQPe_70287Y

# Gold Performance Forecasting: A Machine Learning Approach with Economic Data

# Step-1 : *Data collection, analysis and cleaning.*
"""

# To install required packages and import libraries.
import yfinance as yf
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime

# Function to get the data.
def get_data(start='2000-01-01'):
    """
    To download all the required data from Yahoo finance using yfinance-
    library.(From 2000 to Today)

    parameters: start= start date of data.

    returns: dictionary of all the downloaded data.
    """

    # To download all the required data from Yahoo finance using yfinance-
    # library.(From 2000 to Today)
    # Gold futures.
    gold = yf.download('GC=F', start=start, progress=False)
    # Treasury yield.(thirty years treasury yield)
    treasury_yield = yf.download('^TYX', start=start, progress=False)
    # USD Index.
    usd_index = yf.download('DX=F', start=start, progress=False)
    # Volatility Index (VIX).
    vix = yf.download('^VIX', start=start, progress=False)
    # US oil futures.
    oil = yf.download('CL=F', start=start, auto_adjust=True)
    # Silver futures.
    silver = yf.download('SI=F', start=start, progress=False)

    # To download inflation data (CPI) from federal reserve economic data (FRED).
    cpi_url = "https://fred.stlouisfed.org/graph/fredgraph.csv?id=CPIAUCSL"
    cpi_data = pd.read_csv(cpi_url, index_col=0, parse_dates=True)
    cpi_data.columns = ['CPI']

    # To keep CPI data from year 1999 onwards.
    # # All other data starts from year 2000 but here we need one more year to
    # # calculate anual inflation for year 2000.

    # Convert start to datetime.
    start_date = pd.to_datetime(start)

    # Calculate CPI start date (1 year before start date).
    cpi_start_date = start_date - pd.DateOffset(years=1)
    cpi_start_str = cpi_start_date.strftime('%Y-%m-%d')

    cpi_data = cpi_data[cpi_data.index >= cpi_start_str]

    # To calculate annual inflation rate.
    # For example: march,2024-march,2025; april,2024- april,2025 etc..
    cpi_data['Inflation_Annual'] = cpi_data['CPI'].pct_change(12) * 100  # Year-over-year

    # To keep CPI data from 2000-01-01 onwards for analysis as all other data is from
    # year 2000.
    cpi_data_final = cpi_data[cpi_data.index >= start]

    # Resample to daily frequency with forward fill.
    inflation_annual_daily = cpi_data_final['Inflation_Annual'].resample('D').ffill()

    return {
        'gold': gold,
        'treasury_yield': treasury_yield,
        'usd_index': usd_index,
        'vix': vix,
        'oil': oil,
        'silver': silver,
        'inflation_annual': inflation_annual_daily
    }

dataframe = get_data(start='2000-01-01')

# To check each downloaded data.
datasets_to_check = {
    'Gold': dataframe['gold'],
    'Treasury_yield': dataframe['treasury_yield'],
    'USD Index': dataframe['usd_index'],
    'VIX': dataframe['vix'],
    'US Oil': dataframe['oil'],
    'Silver': dataframe['silver'],
    'Inflation Annual Daily': dataframe['inflation_annual']
}

for name, data in datasets_to_check.items():
    print(f"\n=== {name.upper()} ===")
    print(f"Shape: {data.shape}")
    print(f"Date Range: {data.index[0]} to {data.index[-1]}")
    print("\nFirst 3 rows:\n")
    print(data.tail(3))
    print("\nData types:\n")
    print(data.dtypes)
    print(f"Missing values: {data.isnull().sum().sum()}")

    print("-" * 50)
    print("-" * 50)

# To check if all the data is in same range or not.
print("\nDATE RANGE COMPARISON")
print("=" * 50)

for name, data in datasets_to_check.items():

    # String representation used to avoid errors.
    start_date = str(data.index[0])[:10]  # Get first 10 characters (YYYY-MM-DD)
    end_date = str(data.index[-1])[:10]

    print(f"{name:25} | {start_date} to {end_date} | {len(data):6} records")

# function to combine all the data we collected with it's daily close.

def combine_market_data(data):

    """
    This function helps to create a combined dataset of all collected data with-
    it's daily close.

    Parameters: data (dict): A dictionary containing different market datasets.

    Returns: combined_data (pandas.DataFrame): A combined dataset with all-
             features aligned to daily frequency.

    """
    # Now we can combine all the datasets into one dataset. we require only close
    # price from each day for further analysis.

    # create a copy to avoid modifying original dataframe.
    data = data.copy()

    # To initialize combined dataframe.
    combined_data = pd.DataFrame()

    # To extract close prices from each dataset.
    combined_data['Gold_Price'] = data['gold'][('Close', 'GC=F')]
    combined_data['Treasury_yield'] = data['treasury_yield'][('Close', '^TYX')]
    combined_data['USD_Index'] = data['usd_index'][('Close', 'DX=F')]
    combined_data['VIX'] = data['vix'][('Close', '^VIX')]
    combined_data['OIL'] = data['oil'][('Close', 'CL=F')]
    combined_data['SILVER'] = data['silver'][('Close', 'SI=F')]

    # Inflation annual has different end date than other data.
    # Inflation data we get every month but it is for the last month. For example
    # current month is october so we get the inflation data of september in the
    # starting of october. This data don't change daily so we can forward fill it
    # with the last known value.
    # So here we will forward fill it till last date of gold dataset.
    target_end = data['gold'].index[-1]

    inflation_annual_extended = data['inflation_annual'].reindex(
        pd.date_range(start=data['inflation_annual'].index[0], end=target_end, freq='D')
        ).ffill()

    # Inflation annual has only one value in dataset so we do not need to
    # extract close price from it.
    combined_data['Inflation_Annual'] = inflation_annual_extended

    # Remove any missing values from the combined dataset.
    combined_data = combined_data.dropna()

    return combined_data

combined_df = combine_market_data(dataframe)

print(f"Shape: {combined_df.shape}")
print(f"Date range: {combined_df.index[0]} to {combined_df.index[-1]}")
print("\nCombined data information")
print("=" * 40 + "\n")
print(combined_df.info())
print("\nMissing values:")
print(combined_df.isnull().sum())
print("\nBasic statistics:")
print(combined_df.describe())

"""# Step-2 : *Data visualization.*"""

# Function to plot all the features collected in combined dataframe.

def plot_combined_data(combined_df):

    """
    This function helps to plot all the features fromk the dataframe.

    Parameters: combined_df: A combined dataset with all-
                features aligned to daily frequency.

    Returns: None
    """

    # To create a list of features available in the dataframe.
    available_columns = combined_df.columns.tolist()

    # To initialize subplots.
    fig, axes = plt.subplots(4, 2, figsize=(20,30)) # 4 rows, 2 columns, total 8 subplots.
    fig.suptitle('All features from combined dataset\n', fontsize=24, fontweight='bold')
    axes = axes.flatten() # To create 1D array to iterate through subplots easily.

    # To define plot configurations for each variable.
    plot_config = {
        'Gold_Price': {'color': 'gold', 'title': 'Gold Price', 'ylabel': 'Price ($)'},
        'SILVER': {'color': 'darkgray', 'title': 'Silver Price', 'ylabel': 'Price ($)'},
        'OIL': {'color': 'black', 'title': 'Oil Price', 'ylabel': 'Price ($)'},
        'Treasury_yield': {'color': 'red', 'title': 'Treasury Yield', 'ylabel': 'Yield (%)'},
        'USD_Index': {'color': 'green', 'title': 'USD Index', 'ylabel': 'Index Value'},
        'VIX': {'color': 'purple', 'title': 'VIX (Volatility)', 'ylabel': 'VIX Level'},
        'Inflation_Annual': {'color': 'blue', 'title': 'Annual Inflation', 'ylabel': 'Inflation (%)'}
    }

    # To plot subplots for each variables.
    for i, column in enumerate(available_columns):
        if i < len(axes):
            config = plot_config[column]
            axes[i].plot(combined_df.index, combined_df[column], color=config['color'], linewidth=1.5)
            axes[i].set_title('\n' + config['title'], fontweight='bold', fontsize=18)
            axes[i].set_ylabel(config['ylabel'], fontsize=12, fontweight='bold')
            axes[i].set_xlabel('Year', fontsize=12, fontweight='bold')
            axes[i].grid(False)
            axes[i].tick_params(axis='x', rotation=45)

    # To hide unused subplot.
    for i in range(len(available_columns), len(axes)):
        axes[i].set_visible(False)

    plt.tight_layout()
    plt.show()

plot_combined_data(combined_df)

# Function to visualize the correlation between gold and inflation annual.

def plot_gold_inflation_correlation(df):

    """
    This function helps to plot 1-year rolling correlation between Gold Price
    and Inflation Annual.

    Parameters: df = dataframe.
    """

    # To calculate 1-year rolling correlation between gold and inflation.
    # window=252 as there are roughly 252 trading days in a year.
    rolling_corr = df['Gold_Price'].rolling(window=252).corr(df['Inflation_Annual'])

    # To create the correlation plot.
    plt.figure(figsize=(14, 8))
    plt.plot(rolling_corr.index, rolling_corr, color='purple', linewidth=2.5, label='Gold-Inflation Correlation')

    # To add shaded regions for positive/negative correlation.
    plt.fill_between(rolling_corr.index, rolling_corr, 0, where=rolling_corr >= 0,
                     color='green', alpha=0.2, label='Positive Correlation')
    plt.fill_between(rolling_corr.index, rolling_corr, 0, where=rolling_corr <= 0,
                     color='red', alpha=0.2, label='Negative Correlation')

    plt.axhline(y=0, color='black', linestyle='--', alpha=0.7, linewidth=1)
    plt.title('1-Year Rolling Correlation: Gold Price vs Inflation\n', fontsize=18, fontweight='bold')
    plt.ylabel('Correlation Coefficient', fontsize=12, fontweight='bold')
    plt.xlabel('Date', fontsize=12, fontweight='bold')
    plt.grid(True, alpha=0.4)
    plt.legend()
    plt.tight_layout()
    plt.show()

plot_gold_inflation_correlation(combined_df)

# Function to visualize gold behaviour during high inflation.

def plot_gold_vs_inflation(df):

    """
    This function helps to plot gold prices during high inflation periods.

    Parameters: df = Combined dataset with financial variables

    Returns: high_inflation_periods = DataFrame containing high inflation periods
    """

    high_inflation_threshold = df['Inflation_Annual'].quantile(0.70)
    high_inflation_periods = df[df['Inflation_Annual'] >= high_inflation_threshold]

    plt.figure(figsize=(12, 6))
    plt.plot(df.index, df['Gold_Price'], color='darkgray', label='Gold_price')
    scatter = plt.scatter(high_inflation_periods.index, high_inflation_periods['Gold_Price'],
                         c=high_inflation_periods['Inflation_Annual'], cmap='plasma_r',
                         s=20, alpha=0.7, label='High Inflation Periods')

    # To set the colorbar to threshold.
    vmin = high_inflation_threshold
    vmax = high_inflation_periods['Inflation_Annual'].max()
    scatter.set_clim(vmin=vmin, vmax=vmax)
    cbar = plt.colorbar(scatter)
    cbar.set_label('Inflation Rate (%)')
    ticks = [vmin] + list(np.linspace(vmin, vmax, 6)[1:])
    cbar.set_ticks(ticks)
    cbar.set_ticklabels([f"{t:.2f}" for t in ticks])

    plt.title('Gold prices during high inflation periods\n', fontsize=18, fontweight='bold')
    plt.ylabel('Price', fontsize=12, fontweight='bold')
    plt.xlabel('Date', fontsize=12, fontweight='bold')
    plt.legend()
    plt.xticks(pd.date_range(start=df.index.min(), end=df.index.max(), freq='4YS'))
    plt.show()

    return high_inflation_periods

high_inflation_periods = plot_gold_vs_inflation(combined_df)

# To check the correlation of all the features with gold.
print("\ncorrelation with gold")
print("=" * 35)
daily_c = combined_df.pct_change().dropna()
correlations = daily_c.corr()['Gold_Price'].sort_values(ascending=False)
print(correlations)

# Function to plot correlation heatmap.

def plot_correlation_heatmap(df, figsize):

    """
    This function helps to plot correlation heatmap for the dataset.

    Parameters: df = dataframe.
                figsize = tuple, Figure size for the heatmap.

    """

    # To calculate correlation matrix of the dataframe.
    corr_matrix = df.corr()

    # To create heatmap using correlation matrix.
    plt.figure(figsize=figsize)

    # To mask the upper triangle for cleaner output.
    mask = np.triu(np.ones_like(corr_matrix, dtype=bool))

    sns.heatmap(corr_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,
                fmt='.3f')

    plt.title('Correlation matrix', fontsize=18, fontweight='bold')
    plt.tight_layout()
    plt.show()

corr_matrix = plot_correlation_heatmap(combined_df,(10,8))

"""# Step-3 : *Machine Learning.*

"""

# To install required packages and import libraries.

from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix
import warnings
warnings.filterwarnings('ignore')

"""

* Aim for this machine learning project is to predict gold price and direction
on weekly basis.
* Model is trained on lagged data of major (+ and -) correlated features of cobined_df dataframe and some technical indicators which I have created in below functions.





"""

# Aim for the project is to predict gold price and direction for next month.
# So to train model based on monthly price behaviours I created below function.

# Function to convert combined dataset to monthly data and
# create features for monthly prediction.

def create_monthly_dataset(df):

    """
    This function helps to convert combined dataset to monthly data and
    create features for monthly prediction.

    Parameters: df = Combined dataset with financial variables.

    Returns: monthly_data = Monthly dataset with technical indicators.

    """

    # To resample dataframe to monthly data (using end-of-month).
    monthly_data = df.resample('M').last()
    print(f"Date range: {monthly_data.index.min()} to {monthly_data.index.max()}")

    # To create monthly technical indicators for gold.
    # Moving average = 3 and 6 months, momentum of last three months, rate of
    # change for last 3 months and volatility in gold for last 6 months.
    monthly_data['Gold_MA_3'] = monthly_data['Gold_Price'].rolling(3).mean()  #.shift(1)
    monthly_data['Gold_MA_6'] = monthly_data['Gold_Price'].rolling(6).mean()
    monthly_data['Gold_Momentum_3'] = monthly_data['Gold_Price'] - monthly_data['Gold_Price'].shift(3)
    monthly_data['Gold_ROC_3'] = monthly_data['Gold_Price'].pct_change(3)
    returns = monthly_data['Gold_Price'].pct_change()
    monthly_data['Gold_Volatility_6'] = returns.rolling(6).std()

    # To get the gold and silver ratio for one month.
    monthly_data['Gold_Silver_Ratio'] = monthly_data['Gold_Price'] / monthly_data['SILVER']

    # To creat economic feature of real yield for 1 month.
    # Real yield calculation based on Federal Reserve research: GÃ¼rkaynak, Sack, & Wright (2008)
    monthly_data['Real_Yield'] = monthly_data['Treasury_yield'] - monthly_data['Inflation_Annual']

    # To create lagged features for 1 month and 3 months for all other
    # features.(using end-of-month values)
    for col in ['Treasury_yield', 'USD_Index', 'VIX', 'OIL', 'SILVER', 'Inflation_Annual']:
        monthly_data[f'{col}_lag1'] = monthly_data[col].shift(1)
        monthly_data[f'{col}_lag3'] = monthly_data[col].shift(3)

    # To create target direction using next month's price direction.
    monthly_data['Target_Direction'] = (monthly_data['Gold_Price'].shift(-1) > monthly_data['Gold_Price']).astype(int)

    monthly_data = monthly_data.dropna()
    return monthly_data

# Function for the model training.

def train_models(X, y):

  """
  This function helps to train the models random forest, XGBoost and SVM.

  Parameters: X = Features.
              y = Target variable.

  Returns: results = Dictionary containing model performance metrics.

  """
  # To initialize models with parameters.
  models = {'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=5, random_state=42),
        'XGBoost': XGBClassifier(n_estimators=200, max_depth=4, learning_rate=0.1, random_state=42),
        'SVM': SVC(kernel='rbf', probability=True, random_state=42)   }

  # To split data into 80-20 ratio.
  split_point = int(len(X) * 0.8)

  X_train = X.iloc[:split_point]
  X_test = X.iloc[split_point:]
  y_train = y.iloc[:split_point]
  y_test = y.iloc[split_point:]

  results = {}

  for model_name, model in models.items():
      if model_name == 'SVM':
        # SVM needs to be scaled.
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        model.fit(X_train_scaled, y_train)
        y_pred = model.predict(X_test_scaled)
      else:
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)

      accuracy = accuracy_score(y_test, y_pred)
      precision = precision_score(y_test, y_pred, zero_division=0)
      f1 = f1_score(y_test, y_pred, zero_division=0)

      # To save the models performance metrics.
      results[model_name] = {
          'accuracy': accuracy,
          'precision': precision,
          'f1_score': f1,
          'model': model}

  return results, X_test, y_test

"""Execution of machine learning models to predict the gold price based on monthly data."""

# To create the main function to execute the models and store it's results.

def main(df):

  """
  This function helps to execute the models and store it's results.

  Parameters: df = Combined dataset with financial variables.

  Returns: results = Dictionary containing model performance metrics.
           X_test = Features for testing.
           y_test = Target variable for testing.

  """

  # To create monthly dataset.
  monthly_df = create_monthly_dataset(df)

  # To prepare features without target direction and current gold price.
  feature_columns = [col for col in monthly_df.columns
                    if col not in ['Target_Direction', 'Gold_Price']]

  X = monthly_df[feature_columns]
  y = monthly_df['Target_Direction']

  print(f"Dataset: {len(X)} samples, {len(feature_columns)} features")

  # To call the train models function.
  results, X_test, y_test = train_models(X, y)

  return results, X_test, y_test

results, X_test, y_test = main(combined_df)

# To display results of model performance.
print("\nModel performace:\n")
print("    Model     | Accuracy | Precision | F1-Score")
print("--------------|----------|-----------|----------")
for model_name, metrics in results.items():
    print(f"{model_name:^13} | {metrics['accuracy']:^8.3f} | {metrics['precision']:^8.3f}  |{metrics['f1_score']:^8.3f}")

"""Hyperparameter tunning"""

# To create monthly dataset.
monthly_df = create_monthly_dataset(combined_df)

# To prepare features without target direction and current gold price.
feature_columns = [col for col in monthly_df.columns
                    if col not in ['Target_Direction', 'Gold_Price']]

X = monthly_df[feature_columns]
y = monthly_df['Target_Direction']

from sklearn.model_selection import TimeSeriesSplit, GridSearchCV

def train_random_forest_with_tuning(X, y):
    """
    Train Random Forest with hyperparameter tuning and cross-validation
    """
    print("=" * 60)
    print("RANDOM FOREST HYPERPARAMETER TUNING")
    print("=" * 60)

    # Split data
    split_point = int(len(X) * 0.8)
    X_train_val = X.iloc[:split_point]
    X_test = X.iloc[split_point:]
    y_train_val = y.iloc[:split_point]
    y_test = y.iloc[split_point:]

    # Time Series Cross Validation
    tscv = TimeSeriesSplit(n_splits=5)

    # Hyperparameter grid
    param_grid = {
        'n_estimators': [100, 200, 300],
        'max_depth': [3, 5, 7, None],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    }

    # Grid Search with Time Series CV
    rf = RandomForestClassifier(random_state=42)
    grid_search = GridSearchCV(
        rf, param_grid, cv=tscv, scoring='accuracy',
        n_jobs=-1, verbose=1
    )

    print("Performing grid search...")
    grid_search.fit(X_train_val, y_train_val)

    # Best model
    best_rf = grid_search.best_estimator_

    # Calculate accuracies
    train_accuracy = best_rf.score(X_train_val, y_train_val)
    test_accuracy = best_rf.score(X_test, y_test)

    # Cross-validation accuracy
    cv_accuracy = grid_search.best_score_

    # Predictions
    y_pred = best_rf.predict(X_test)
    precision = precision_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)

    print(f"\nBest Parameters: {grid_search.best_params_}")
    print(f"Training Accuracy: {train_accuracy:.3f}")
    print(f"Validation Accuracy (CV): {cv_accuracy:.3f}")
    print(f"Testing Accuracy: {test_accuracy:.3f}")
    print(f"Precision: {precision:.3f}")
    print(f"F1-Score: {f1:.3f}")

    # Feature importance
    feature_importance = pd.DataFrame({
        'feature': X.columns,
        'importance': best_rf.feature_importances_
    }).sort_values('importance', ascending=False)

    print(f"\nTop 10 Features:")
    print(feature_importance.head(10).to_string(index=False))

    return {
        'model': best_rf,
        'train_accuracy': train_accuracy,
        'val_accuracy': cv_accuracy,
        'test_accuracy': test_accuracy,
        'precision': precision,
        'f1_score': f1,
        'feature_importance': feature_importance
    }

# Run Random Forest tuning
rf_results = train_random_forest_with_tuning(X, y)